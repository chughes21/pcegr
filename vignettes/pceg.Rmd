---
title: "The pcegr Package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The pcegr Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(kableExtra)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The pcegr package can be used to fit Poisson Chain Event Graphs (PCEGs) and Zero-Inflated Poisson Chain Event Graphs (ZIPCEGs) to data. We will demonstrate the functionality of the package using a simulated example based around knee pain. 

Suppose a study is carried out on the instances of knee pain in a population. For each individual, their age, weight and whether they have injured their legs before are recorded, along with the amount of instances of knee pain they suffered over a certain period of time, in years. This period of time is variable between individuals, and varies uniformly between 1 day and 2 years.

Each of the three covariates are binary, with categories and associated binary values:
+ Age (A): Old (0) or Young (1)
+ (Over)weight (W): Yes (0) or No (1)
+ History (H): Yes (0) or No (1)

while the response variable of Knee Pain (K) is assumed to come from a Zero-Inflated Poisson process where the risk probability and intensity is dependent on these three covariates. For each individual, they are assumed to have a latent risk state (S), either At Risk (0) or Risk Free (1), where those who are At Risk have a nonzero probability of suffering an instance of knee pain. 

For an individual with risk probability $\pi$ and Poisson intensity $\lambda$, the expected number of event counts $Y$ observed over time $t$ is $E[Y] = \pi \lambda t$. Assume instead that a Poisson process with rate $\mu$ was used to model the counts, with rate estimated as $\hat{\mu}$. We would expect (for a large sample size) that \[\hat{\mu} \simeq \pi \lambda.\] Now, if we assume for two populations with different covariates that having the same rate $\lambda$ means they have the same risk probability $\pi$, a significant simplification, then we can fit either a PCEG model or ZIPCEG model to the data set, and the estimated rates and risk probabilities should be in line with the relationship above.

As these models are based on staged trees, we will use leaf to refer to a specific covariate combination, and also the individuals with that specific covariate combination. We use the notation $l_i$ for the $i^{\text{th}}$ leaf in the tree, and assume it has rate $\lambda_i$ and associated risk probability $\pi_i$. A leaf stage $u$ contains leaves that are assumed to have the same rate. That is: $l_i, l_j \in u \Rightarrow \lambda_i = \lambda_j$.

Generally, we would not assume that $\lambda_i = \lambda_j \Rightarrow \pi_i = \pi$, but for the purposes of simulating the data in this package we have. This is a simplification, but means that when a PCEG is fit instead of a ZIPCEG, the merging for the leaves will be the same, but the PCEG will have lower posterior expected values, as outlined above. We have chosen this simplifying assumption in order to easily compare the PCEG and ZIPCEG models.  

We have thus simulated $N=10000$ observations for the knee pain data set from a zero-inflated Poisson distribution with uniformly distributed observation times. The data has been simulated under the following conditional independence statements:
+ Weight is independent of Age: W $\indep$ A;
+ History is independent of Weight given Age: H $\indep$ W $\vert$ A;
+ Knee Pain (and thus State) is independent of Age given History and the individual is Overweight: K, S $\indep$ A $\vert$ H, W = "Over"

In the following table, we can see each conditional transition probability, informed by the conditional independence statements above. Each probability has its definition alongside its associated stage and situations.
```{r}
cov_probs
```

For each leaf stage, we have the definition of the stage and its constituent leaves based on the conditional independence statements above, alongside the associated risk probability and rate.
```{r}
leaf_params
```

We can thus isolate the true values for $\pi$ and $\lambda$, along with what should be the PCEG estimate.
```{r}
true_lambda<-leaf_params$Rate
true_p<-leaf_params$Risk_Prob
pceg_lambda<-true_lambda*true_p;pceg_lambda
```


This simulation creates two data sets. The first, *knee_pain*, is the simulated data set, containing the true risk state for each individual. The second, *knee_pain_obs*, is the observed data set, which is simply *knee_pain* with the risk states removed. We can investigate these:
```{r}
library(pcegr)
head(knee_pain)
summary(knee_pain)
summary(knee_pain_obs)
```

First, we will fit a PCEG model to the data set. This requires specifying an effective sample size. The default choice for CEGs is usually the greatest number of categories a single variable takes, in this case 2. A sensitivity analysis can be carried out on the effects of this choice. 

As there are $2^3 = 8$ leaves, we will assume each has a prior weight of $a = \tfrac{2}{8} = 0.25$. In order to enforce a prior mean for the rate of 2.5, the simple average for the data set, we choose $b = \tfrac{0.25}{2.5}=0.1$. If we were to desire more bespoke priors for each leaf, they could be input as vectors rather than scalars.
```{r}

pmod<-pceg(knee_pain_obs,2,TRUE,TRUE, gamma_alpha = 0.25,gamma_beta = 0.1)
pmod$result
```

We can see that the model has correctly identified that the individuals of either Age who are Overweight with a History of injury are in the same stage (8), and likewise for those with No History (9). It has also correctly identified that History is independent of Weight given Age (4 and 5). 

We now can estimate the posterior expected values of the tranisiton probabilities for the covariates, and the rates for the response. The transition probabilities can be compared to *cov_probs*, while we have included what the PCEG estimate should be for $\lambda$, based on the true $\pi$ and $\lambda$.
```{r}
for(i in 0:2){
  print(value_extractor(knee_pain_obs,pmod,level_rel_final = i-3,zip=FALSE))
}
value_extractor(knee_pain_obs,pmod,level_rel_final = 0,true_value = pceg_lambda, zip=FALSE)
```
As can be seen, while the model is misspecified, it correctly identifies the transition probabilities, and the estimates of the rates are close to what we would expect.

We can also find 95% highest density intervals for these parameters. For example:
```{r}
hdi_gamma_extractor(knee_pain_obs,pmod,zip=FALSE)
hdi_beta_extractor(knee_pain_obs,pmod,level_rel_final = -1, zip=FALSE)
```

We can also check the log marginal likelihood and Chi-square calculation for the model, to assess the fit. 

```{r}
pmod$lik
expected_count_calculator(knee_pain_obs,pmod,zip=FALSE)
```
In the Chi-square contribution matrix, we can see some large values. In particular, for the leaves with low rates, for example the first row, we can see large contributions for the higher event counts. This is because there are a much higher number of observed counts greater than 3 than we would expect based on the small rate. In contrast, for the leaves with higher rates, such as 4, 6 and 8, we can see that the contributions for the zero counts are much higher. This is because there are much more observed zero counts than would be expected with such a high rate. 

These results are all indicative of the true underlying model instead being a zero-inflated Poisson distribution. We now fit a ZIPCEG model to the data. 

TO fit a ZIPCEG model, we must first choose the method of parameter estimation. As time is variable, we cannot use the MLE or method of moments estimators. Thus, the choices are Gibbs sampling ("Gibbs"), numerical likelihood optimisation ("nlm") or the Expectation-Maximisation algorithm ("EM"). We will perform model selection using the first two choices.

We will keep the same effective sample size as for the PCEG, but we must consider the prior on the leaves. For a ZIPCEG, we want the risk free leaves to have zero prior hyperparameters, and the risk leaves will have the same hyperparameters as for the PCEG. The priors must be input as vectors, where every odd element is a risk free leaf and thus 0. There are 16 leaves in total, 8 of each type.
```{r}
a<-rep(c(0,0.25),8)
b<-a/2.5
```

For the Gibbs sampler, we must also specify the hyperparameters of the Beta($c,d$) prior for the risk probability. We will assume each risk probability has the same prior. This prior should be cohesive with the prior in the tree itself, and thus we should have $c = d = \tfrac{2}{16} = 0.125$ for each risk probability.
```{r}
c<-0.125
d<-0.125
```
We will also run the Gibbs sampler for $N=10000$ iterations. When the parameeters are estimated using the Gibbs sampler, we will impute the states stochastically.
```{r}
zipmod1<-zipceg(knee_pain_obs,"Gibbs",iter=10000,variable_time = TRUE, stoch_imputation = TRUE, gamma_alpha = a, gamma_beta = b, beta_c = c, beta_d = d)
zipmod1$result
```
We can see that the model correctly merges the risk states (8 and 9)and the rates (15 and 16). We can also see that all of the risk free leaves are merged together into one stage (12). The covariate relationships have also been preserved from the PCEG. 

We now compare the goodness of fit to the PCEG. First, we calculate the log marginal likelihood and the Chi-square calculation. 
```{r}
zipmod1$lik
expected_count_calculator(knee_pain_obs,zipmod1,zip=TRUE)
```
We can see that the Chi-square value is significantly lower for the ZIPCEG model, which is to be expected as the model was simulated assuming a zero-inflated Poisson distribution.

As for the log marginal likelihood, this is not directly comparable to the PCEG model, due to the extra covariate and different priors. The key here is to fit a ZIPCEG model to the data with the same prior as the regular ZIPCEG model, except every individual is assumed to be at risk. This can be done with the *pceg* function as follows:
```{r}
data.risk<-state_imputer(knee_pain_obs,all_risk=TRUE)
pmod.bf<-pceg(data.risk,2,TRUE,TRUE,TRUE,gamma_alpha=a,gamma_beta=b)
pmod.bf$lik
```
This is the exact same model as the regular PCEG, except we can see that the log marginal likelihood has decreased. This log marginal likelihood is comparable to the ZIPCEG.
```{r}
zipmod1$lik-pmod.bf$lik
```
Hence, the ZIPCEG is a significantly better fit to the data than the PCEG according to the log Bayes factor also. 

We can also fit the ZIPCEG using the *nlm* method instead. Notably, this doesn't require a Beta($c,d$) prior, or a number of iterations. It is also significantly faster.  
```{r}
zipmod2<-zipceg(knee_pain_obs,"nlm",variable_time = TRUE, stoch_imputation = TRUE, gamma_alpha = a, gamma_beta = b)
zipmod2$result
zipmod2$lik
expected_count_calculator(knee_pain_obs,zipmod2)
```
Comparing the two ZIPCEG models fitted appears to favour the Gibbs sampler method.
```{r}
zipmod1$lik-zipmod2$lik
expected_count_calculator(knee_pain_obs,zipmod1)$chi_sq-expected_count_calculator(knee_pain_obs,zipmod2)$chi_sq
```
However, both of these models are the result of one iteration, and the ZIPCEG model selection process is not deterministic. We can thus carry out the model selection a number of times, for example 100, and compare the risk probabilities and rates for each leaf, as well as select the MAP model from those iterations. Comparing the probabilities and rates for each leaf gives an idea of how the leaves merge with each other, as those who have similar plots will merge regularly. This is useful for data that is not simulated, as there may be significant variability from iteration to iteration. 

we will use violin plots to visualise, but there are options to use histograms, scatter plots, or line plots. We will use the *nlm* method, due to its lower computational cost per iteration. 
```{r}
mapmod<-zipceg.iter(knee_pain_obs,"nlm",iter_total=100,variable_time = TRUE,gamma_alpha=a,gamma_beta=b)$mod
mapmod.alt<-zipceg.iter(knee_pain_obs,"nlm",iter_total=100,variable_time = TRUE,plot_rates=FALSE,plot_probs=TRUE,gamma_alpha=a,gamma_beta=b)
```
We can see in the plot of the rates the merging that is present for leaves 3 and 7, and 4 and 8. The violin plots are identical, indicating that they always merge, and so we can be confident in the result from our initial model selection. In general, the violin plots are quite tight, which is a result of the large sample size and demarcation between the leaves. The risk probabilities also show these mergings, although not as consistently as for the rates. For example, leaf 4 occasionally merges with leaf 6 instead of 8. In both plots, leaf 5 is by far the most variable, and this is a result of it having the smallest sample size.

After looking at the plots above, we can be confident in the mergings produced by the single iteration of the model selection process. However, the way the states are imputed can still significantly affect the log marginal likelihood of the final model. We have selected a MAP model, and we can investigate its properties.
```{r}
mapmod$result
mapmod$lik
mapmod$lik-zipmod1$lik
expected_count_calculator(knee_pain_obs,mapmod,zip=TRUE)$chi_sq-expected_count_calculator(knee_pain_obs,zipmod1,zip=TRUE)$chi_sq

```
Interestingly, the MAP model outperforms the single iteration of the Gibbs sampler in terms of log marginal likelihood, but not in terms of the Chi-square. We can compare the matrix of their Chi-square contributions to examine why.
```{r}
expected_count_calculator(knee_pain_obs,mapmod,zip=TRUE)$chi.mat-expected_count_calculator(knee_pain_obs,zipmod1,zip=TRUE)$chi.mat
```
We can see that there are some differences between the two models for leaves 1, 3 and 6. We now look at the posterior expected values of $\pi_$ and $\lambda_i$ from the MAP model. We also compare these to the true values of $\lambda_i$ and $\pi_i$. Note that the estimates below are for each stage, not leaf. For example, stage 3 contains leaves 3 and 7. The first row for $\lambda$ is the risk free stage, and so the second row is stage 1.  
```{r}
value_extractor(knee_pain_obs,mapmod,true_value=true_lambda)
value_extractor(knee_pain_obs,mapmod,level_rel_final = -1,true_value=true_p)

```
We can also calculate the expected values for the single iteration of the Gibbs sampler.
```{r}
value_extractor(knee_pain_obs,zipmod1,true_value=true_lambda)
value_extractor(knee_pain_obs,zipmod1,level_rel_final = -1,true_value=true_p)
```
Rather unexpectedly, the *zipmod1* appears to generally outperform *mapmod* in estimating the true values of the parameters. The key to why this happens lies in the imputation of states. 

We will once again fit a PCEG model, except this time to the true data. 
```{r}
truemod<-pceg(knee_pain,2,TRUE,TRUE,gamma_alpha=a,gamma_beta=b,zip=TRUE)
truemod$lik
truemod$result
value_extractor(knee_pain,truemod,true_value=c(0,true_lambda),zip=FALSE)
value_extractor(knee_pain,truemod,level_rel_final=-1,true_value=true_p,zip=FALSE)
```


